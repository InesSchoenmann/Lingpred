{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0adf827",
   "metadata": {},
   "source": [
    "# Making an X Matrix of the Mel-Spectrogramm of the audio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7a9835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(os.path.abspath(\"../lingpred_audio/\"))\n",
    "from audio import word_avg_sg, get_words_onsets_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6c5a690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the data set and number of mels\n",
    "dataset               = 'Goldstein'\n",
    "mels                  = 8\n",
    "use_real_word_offsets = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eca5e845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "if dataset== 'Goldstein':\n",
    "    acoustic_model = word_avg_sg(subject=1, session=1, n_mels=8, dataset = dataset,task = 1, use_real_word_offsets=use_real_word_offsets) \n",
    "# otherwise we will have to loop over sessions (Armeni) or tasks (Gwilliams)\n",
    "# see code two cells down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de6fdebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5136, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acoustic_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76ab055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "if dataset == 'Goldstein':\n",
    "\n",
    "    audio_dir = '../audio/'\n",
    "\n",
    "    if use_real_word_offsets:\n",
    "        filename  = audio_dir+'{}/acoustic_model_{}_mels_averaged_per_word_using_word_offsets.pkl'.format(dataset, mels)\n",
    "    else:\n",
    "        filename  = audio_dir+'{}/acoustic_model_{}_mels_averaged_per_word_using_next_word_onset_as_offset.pkl'.format(dataset, mels)\n",
    "    \n",
    "    f = open(filename,\"wb\")\n",
    "    pickle.dump(acoustic_model,f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484a3386",
   "metadata": {},
   "source": [
    "## For the Armeni & Gwilliams datasets there are several sessions over which we must loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c952a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject  = 1\n",
    "task     = 0  # uncomment for running for Armeni dataset\n",
    "#session = 0 # uncomment for running for Gwilliams dataset\n",
    "\n",
    "tasks    = ['0', '1', '2', '3']\n",
    "sessions = [1]\n",
    "mels     = [8]\n",
    "dataset = \"Armeni\"\n",
    "\n",
    "# for the Gwilliams dataset we loop over tasks || for the Armani over sessions\n",
    "for mel in mels:\n",
    "    \n",
    "    acoustic_model = np.empty(shape=(0, mel+1))\n",
    "    \n",
    "    #for task in tasks: \n",
    "    for session in sessions: # uncomment for running for Armeni dataset\n",
    "        \n",
    "        if subject == 3 and dataset == 'Armani':\n",
    "            if session == 8:\n",
    "                continue\n",
    "        \n",
    "        avg_spec_init_phone = word_avg_sg(subject=subject, session=session, \n",
    "                                                  n_mels=mel, dataset = dataset,\n",
    "                                                  task = task)\n",
    "        print(avg_spec_init_phone.shape)\n",
    "        acoustic_model = np.vstack([acoustic_model, avg_spec_init_phone])\n",
    "\n",
    "    if use_real_word_offsets:\n",
    "        filename  = audio_dir+'{}/acoustic_model_{}_mels_averaged_per_word_using_word_offsets.pkl'.format(dataset, mels)\n",
    "    else:\n",
    "        filename  = audio_dir+'{}/acoustic_model_{}_mels_averaged_per_word_using_next_word_onset_as_offset.pkl'.format(dataset, mels)\n",
    "    \n",
    "    f = open(filename,\"wb\")\n",
    "    pickle.dump(acoustic_model,f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7ee2fd",
   "metadata": {},
   "source": [
    "### ... checking some word off sets and onsets ... for control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b02b9c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>sample</th>\n",
       "      <th>type</th>\n",
       "      <th>value</th>\n",
       "      <th>offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.089189</td>\n",
       "      <td>0.129705</td>\n",
       "      <td>46637.372038</td>\n",
       "      <td>word_onset_01</td>\n",
       "      <td>THE</td>\n",
       "      <td>1.213895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.218895</td>\n",
       "      <td>0.678458</td>\n",
       "      <td>46793.018296</td>\n",
       "      <td>word_onset_01</td>\n",
       "      <td>ADVENTURES</td>\n",
       "      <td>1.892353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.897353</td>\n",
       "      <td>0.089796</td>\n",
       "      <td>47607.167956</td>\n",
       "      <td>word_onset_01</td>\n",
       "      <td>OF</td>\n",
       "      <td>1.982149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.987149</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>47714.923058</td>\n",
       "      <td>word_onset_01</td>\n",
       "      <td>SHERLOCK</td>\n",
       "      <td>2.471037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.476037</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>48301.589725</td>\n",
       "      <td>word_onset_01</td>\n",
       "      <td>HOLMES</td>\n",
       "      <td>3.907772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6101</th>\n",
       "      <td>473.884654</td>\n",
       "      <td>0.209524</td>\n",
       "      <td>613991.929861</td>\n",
       "      <td>word_onset_01</td>\n",
       "      <td>SAID</td>\n",
       "      <td>474.089178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6105</th>\n",
       "      <td>474.094178</td>\n",
       "      <td>0.249433</td>\n",
       "      <td>614243.358433</td>\n",
       "      <td>word_onset_01</td>\n",
       "      <td>HE</td>\n",
       "      <td>475.027046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6110</th>\n",
       "      <td>475.032046</td>\n",
       "      <td>0.269388</td>\n",
       "      <td>615368.800610</td>\n",
       "      <td>word_onset_01</td>\n",
       "      <td>READ</td>\n",
       "      <td>475.296434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6114</th>\n",
       "      <td>475.301434</td>\n",
       "      <td>0.129705</td>\n",
       "      <td>615692.065916</td>\n",
       "      <td>word_onset_01</td>\n",
       "      <td>IT</td>\n",
       "      <td>475.426139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6117</th>\n",
       "      <td>475.431139</td>\n",
       "      <td>0.568707</td>\n",
       "      <td>615847.712174</td>\n",
       "      <td>word_onset_01</td>\n",
       "      <td>ALOUD</td>\n",
       "      <td>475.999847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1258 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           onset  duration         sample           type       value  \\\n",
       "3       1.089189  0.129705   46637.372038  word_onset_01         THE   \n",
       "6       1.218895  0.678458   46793.018296  word_onset_01  ADVENTURES   \n",
       "15      1.897353  0.089796   47607.167956  word_onset_01          OF   \n",
       "18      1.987149  0.488889   47714.923058  word_onset_01    SHERLOCK   \n",
       "24      2.476037  0.698413   48301.589725  word_onset_01      HOLMES   \n",
       "...          ...       ...            ...            ...         ...   \n",
       "6101  473.884654  0.209524  613991.929861  word_onset_01        SAID   \n",
       "6105  474.094178  0.249433  614243.358433  word_onset_01          HE   \n",
       "6110  475.032046  0.269388  615368.800610  word_onset_01        READ   \n",
       "6114  475.301434  0.129705  615692.065916  word_onset_01          IT   \n",
       "6117  475.431139  0.568707  615847.712174  word_onset_01       ALOUD   \n",
       "\n",
       "          offset  \n",
       "3       1.213895  \n",
       "6       1.892353  \n",
       "15      1.982149  \n",
       "18      2.471037  \n",
       "24      3.907772  \n",
       "...          ...  \n",
       "6101  474.089178  \n",
       "6105  475.027046  \n",
       "6110  475.296434  \n",
       "6114  475.426139  \n",
       "6117  475.999847  \n",
       "\n",
       "[1258 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_words_onsets_offsets(dataset=dataset, subject=1, session=1, run=1, task='0', use_real_word_offsets=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cad17460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11298410720582895 -2.783900000000017 1669\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>onset</th>\n",
       "      <th>offset</th>\n",
       "      <th>new_offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>by</td>\n",
       "      <td>566.969828</td>\n",
       "      <td>567.139828</td>\n",
       "      <td>567.174828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>a</td>\n",
       "      <td>567.179828</td>\n",
       "      <td>567.209828</td>\n",
       "      <td>567.304828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>monkey</td>\n",
       "      <td>567.309828</td>\n",
       "      <td>567.739828</td>\n",
       "      <td>568.134828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>Yeah</td>\n",
       "      <td>568.139828</td>\n",
       "      <td>568.359828</td>\n",
       "      <td>568.694828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>just</td>\n",
       "      <td>568.699828</td>\n",
       "      <td>568.829828</td>\n",
       "      <td>568.924828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>as</td>\n",
       "      <td>568.929828</td>\n",
       "      <td>568.979828</td>\n",
       "      <td>569.014828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>I</td>\n",
       "      <td>569.019828</td>\n",
       "      <td>569.129828</td>\n",
       "      <td>569.224828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>just</td>\n",
       "      <td>569.229828</td>\n",
       "      <td>569.399828</td>\n",
       "      <td>569.934828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>yeah</td>\n",
       "      <td>569.939828</td>\n",
       "      <td>570.089828</td>\n",
       "      <td>570.694828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>Yeah</td>\n",
       "      <td>570.699828</td>\n",
       "      <td>570.839828</td>\n",
       "      <td>568.055928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>You</td>\n",
       "      <td>568.060928</td>\n",
       "      <td>568.120928</td>\n",
       "      <td>568.155928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>found</td>\n",
       "      <td>568.160928</td>\n",
       "      <td>568.340928</td>\n",
       "      <td>568.395928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>out</td>\n",
       "      <td>568.400928</td>\n",
       "      <td>568.530928</td>\n",
       "      <td>568.545928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>the</td>\n",
       "      <td>568.550928</td>\n",
       "      <td>568.610928</td>\n",
       "      <td>568.665928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>monkey</td>\n",
       "      <td>568.670928</td>\n",
       "      <td>568.940928</td>\n",
       "      <td>568.955928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>was</td>\n",
       "      <td>568.960928</td>\n",
       "      <td>569.130928</td>\n",
       "      <td>569.185928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>suing</td>\n",
       "      <td>569.190928</td>\n",
       "      <td>569.450928</td>\n",
       "      <td>569.485928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>you</td>\n",
       "      <td>569.490928</td>\n",
       "      <td>569.760928</td>\n",
       "      <td>569.955928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>because</td>\n",
       "      <td>569.960928</td>\n",
       "      <td>570.240928</td>\n",
       "      <td>570.295928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>your</td>\n",
       "      <td>570.300928</td>\n",
       "      <td>570.390928</td>\n",
       "      <td>570.425928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word       onset      offset  new_offset\n",
       "1660       by  566.969828  567.139828  567.174828\n",
       "1661        a  567.179828  567.209828  567.304828\n",
       "1662   monkey  567.309828  567.739828  568.134828\n",
       "1663     Yeah  568.139828  568.359828  568.694828\n",
       "1664     just  568.699828  568.829828  568.924828\n",
       "1665       as  568.929828  568.979828  569.014828\n",
       "1666        I  569.019828  569.129828  569.224828\n",
       "1667     just  569.229828  569.399828  569.934828\n",
       "1668     yeah  569.939828  570.089828  570.694828\n",
       "1669     Yeah  570.699828  570.839828  568.055928\n",
       "1670      You  568.060928  568.120928  568.155928\n",
       "1671    found  568.160928  568.340928  568.395928\n",
       "1672      out  568.400928  568.530928  568.545928\n",
       "1673      the  568.550928  568.610928  568.665928\n",
       "1674   monkey  568.670928  568.940928  568.955928\n",
       "1675      was  568.960928  569.130928  569.185928\n",
       "1676    suing  569.190928  569.450928  569.485928\n",
       "1677      you  569.490928  569.760928  569.955928\n",
       "1678  because  569.960928  570.240928  570.295928\n",
       "1679     your  570.300928  570.390928  570.425928"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#diff = df.offset - df.end\n",
    "#print(diff.mean(), diff.min(), diff.argmin())\n",
    "#df.iloc[1660:1680]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ef08e4",
   "metadata": {},
   "source": [
    "### Ok, this is happening because they are talking over one another here. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
