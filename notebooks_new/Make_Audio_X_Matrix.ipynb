{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0adf827",
   "metadata": {},
   "source": [
    "# Making an X Matrix of the Mel-Spectrogramm of the audio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de7a9835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6c5a690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the data set and number of mels\n",
    "dataset = 'Goldstein'\n",
    "mels    = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eca5e845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/ines/research/Lingpred/audio/podcast_transcript.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset\u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGoldstein\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     acoustic_model \u001b[38;5;241m=\u001b[39m \u001b[43mword_avg_sg\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_mels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGoldstein\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# check shape\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     acoustic_model\u001b[38;5;241m.\u001b[39mshape\n",
      "Cell \u001b[0;32mIn[4], line 40\u001b[0m, in \u001b[0;36mword_avg_sg\u001b[0;34m(subject, session, task, dataset, n_mels)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(run)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# get onset times of the initial phonemes adjusted to onset of the audiofile:\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m df_words \u001b[38;5;241m=\u001b[39m \u001b[43mget_words_onsets_offsets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# audio file name \u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m session\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m10\u001b[39m:\n",
      "Cell \u001b[0;32mIn[4], line 478\u001b[0m, in \u001b[0;36mget_words_onsets_offsets\u001b[0;34m(dataset, subject, session, run, task)\u001b[0m\n\u001b[1;32m    475\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpodcast_transcript.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    476\u001b[0m     filepath  \u001b[38;5;241m=\u001b[39m dir_path \u001b[38;5;241m+\u001b[39m file_name\n\u001b[0;32m--> 478\u001b[0m     df_words \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     df_words\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124monset\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffset\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_words\n",
      "File \u001b[0;32m~/anaconda3/envs/audio_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/audio_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/audio_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/audio_env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/audio_env/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/ines/research/Lingpred/audio/podcast_transcript.csv'"
     ]
    }
   ],
   "source": [
    "if dataset== 'Goldstein':\n",
    "    acoustic_model = word_avg_sg(subject=1, session=1, n_mels=8, dataset = 'Goldstein',task = 1)\n",
    "    # check shape\n",
    "    acoustic_model.shape\n",
    "# otherwise we will have to loop over sessions (Armeni) or tasks (Gwilliams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ab055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "if dataset == 'Goldstein':\n",
    "\n",
    "    audio_dir = '/Users/ines/research/Lingpred/audio/'\n",
    "    filename  = audio_dir+'{}/acoustic_model_{}_mels_averaged_per_word.pkl'.format(dataset, mels)\n",
    "    \n",
    "    f = open(filename,\"wb\")\n",
    "    pickle.dump(acoustic_model,f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c952a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject  = 3\n",
    "task     = 0  # uncomment for running for Armeni dataset\n",
    "#session = 0 # uncomment for running for Gwilliams dataset\n",
    "\n",
    "tasks    = ['0', '1', '2', '3']\n",
    "sessions = [1]\n",
    "mels     = [8]\n",
    "dataset = \"Goldstein\"\n",
    "\n",
    "# for the Gwilliams dataset we loop over tasks || for the Armani over sessions\n",
    "for mel in mels:\n",
    "    \n",
    "    acoustic_model = np.empty(shape=(0, mel+1))\n",
    "    \n",
    "    #for task in tasks: \n",
    "    for session in sessions: # uncomment for running for Armeni dataset\n",
    "        \n",
    "        if subject == 3 and dataset == 'Armani':\n",
    "            if session == 8:\n",
    "                continue\n",
    "        \n",
    "        avg_spec_init_phone = word_avg_sg(subject=subject, session=session, \n",
    "                                                  n_mels=mel, dataset = dataset,\n",
    "                                                  task = task)\n",
    "        print(avg_spec_init_phone.shape)\n",
    "        acoustic_model = np.vstack([acoustic_model, avg_spec_init_phone])\n",
    "\n",
    "    filename = '/project/3018059.03/data/{}/acoustic_model_{}_mels_averaged_per_word.pkl'.format(dataset, mel)\n",
    "    \n",
    "    if subject == 3 and dataset == 'Armani':\n",
    "        filename = '/project/3018059.03/data/{}/acoustic_model_without_session_8_{}_mels_averaged_per_word.pkl'.format(dataset, mel)\n",
    "    f = open(filename,\"wb\")\n",
    "    pickle.dump(acoustic_model,f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fac261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_avg_sg(subject:int, session:int, task= '0', dataset='Armani', n_mels=8):\n",
    "    '''\n",
    "    Params:\n",
    "    -------\n",
    "    - Dataset: 'Armani' or Gwilliams\n",
    "    - Subject\n",
    "    - Session\n",
    "    - n_mels: nr of bands for the mel spectogram\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Array of shape (nr_words, n_mels+1)\n",
    "    containing the spectogram information averaged over time for each mel band \n",
    "    '''\n",
    "    avg_sg_all_runs = np.empty(shape=(0, n_mels+1)) # +1 for the variance \n",
    "    \n",
    "    if dataset == 'Armani':\n",
    "        audio_dir = '/project/3018059.03/data/Armani/stimuli/'\n",
    "        # sampling rate MEG data:\n",
    "        sr_meg = 1200\n",
    "        \n",
    "    if dataset == 'Gwilliams':\n",
    "        audio_dir = '/project/3018059.03/data/Gwilliams/'\n",
    "        # sampling rate MEG data:\n",
    "        sr_meg = 1000\n",
    "\n",
    "    if dataset=='Goldstein':\n",
    "        audio_dir = '/Users/ines/research/Lingpred/audio/Goldstein'\n",
    "        sr_meg    = 512\n",
    "        \n",
    "    # get runs in this session\n",
    "    runs = get_runs(dataset, session, subject, task)\n",
    "\n",
    "    \n",
    "    for run in runs:\n",
    "        \n",
    "        print(run)\n",
    "        \n",
    "        # get onset times of the initial phonemes adjusted to onset of the audiofile:\n",
    "        df_words = get_words_onsets_offsets(dataset, subject, session, run, task)\n",
    "        \n",
    "        \n",
    "        # audio file name \n",
    "        if session<10:\n",
    "            audio_run = audio_dir + '0{}_{}.wav'.format(session, run)\n",
    "        else:\n",
    "            audio_run = audio_dir + '{}_{}.wav'.format(session, run)\n",
    "            \n",
    "        if dataset == 'Gwilliams':\n",
    "            audio_run = audio_dir + df_words.sound.unique()[0]\n",
    "\n",
    "        if dataset == 'Goldstein':\n",
    "            audio_run = audio_dir + 'monkey_and_horse.wav'\n",
    "\n",
    "        # waveform (scale) and sampling rate (sr)\n",
    "        scale, sr = librosa.load(audio_run, sr=sr_meg*18)\n",
    "\n",
    "        # make spectrogram \n",
    "        mel_sg   = librosa.feature.melspectrogram(y=scale, sr=sr, hop_length=int(sr/sr_meg), \n",
    "                                                  n_mels=n_mels)\n",
    "        lm_sg    = librosa.power_to_db(mel_sg)\n",
    "        lm_time  = np.arange(1,lm_sg.shape[1]+1)/sr_meg\n",
    "        \n",
    "        # average over the duration of the phoneme for each band:\n",
    "        # resulting array is of shape (nr_phonemes, nr_bands)\n",
    "        discrete_events = discretise_events(lm_sg, lm_time, onset_df=df_words)\n",
    "        \n",
    "        # stack for all runs:\n",
    "        avg_sg_all_runs = np.vstack((avg_sg_all_runs, discrete_events))\n",
    "        \n",
    "    return avg_sg_all_runs\n",
    "\n",
    "def make_acoustic_y_matrix(subject:int, session:int, task= '0', dataset='Armani', n_mels=8,\n",
    "                        only_word_inital_phonemes=True):\n",
    "    ''''\n",
    "    Creates a Mel Spectogram with n_mels + the envelope and that resembles the shape of the neural data. \n",
    "    Hence, it will have the shape (n_mels+1, n_words, n_timepoints)\n",
    "    '''\n",
    "    if dataset == 'Armani':\n",
    "        audio_dir = '/project/3018059.03/data/Armani/stimuli/'\n",
    "        # sampling rate MEG data:\n",
    "        sr_meg = 1200\n",
    "        \n",
    "    if dataset == 'Gwilliams':\n",
    "        audio_dir = '/project/3018059.03/data/Gwilliams/'\n",
    "        # sampling rate MEG data:\n",
    "        sr_meg = 1000\n",
    "    \n",
    "    y_matrix_all_runs = np.empty(shape=(0, n_mels+1, sr_meg*4)) # +1 for the variance \n",
    "    \n",
    "    # get runs in this session\n",
    "    runs = get_runs(dataset, session, subject, task)\n",
    "\n",
    "    for run in runs:\n",
    "        \n",
    "        print(run)\n",
    "        # get onset times of the initial phonemes adjusted to onset of the audiofile:\n",
    "        df_phonemes = get_phonemes_onsets_offsets(dataset, subject, session, run, task, only_word_inital_phonemes)\n",
    "        \n",
    "        # audio file name \n",
    "        if session<10:\n",
    "            audio_run = audio_dir + '0{}_{}.wav'.format(session, run)\n",
    "        else:\n",
    "            audio_run = audio_dir + '{}_{}.wav'.format(session, run)\n",
    "            \n",
    "        if dataset == 'Gwilliams':\n",
    "            audio_run = audio_dir + df_phonemes.sound.unique()[0]\n",
    "\n",
    "        # waveform (scale) and sampling rate (sr)\n",
    "        scale, sr = librosa.load(audio_run, sr=sr_meg*18)\n",
    "\n",
    "        # make spectrogram \n",
    "        mel_sg   = librosa.feature.melspectrogram(y=scale, sr=sr, hop_length=int(sr/sr_meg), \n",
    "                                                  n_mels=n_mels)\n",
    "        lm_sg    = librosa.power_to_db(mel_sg)\n",
    "        lm_time  = np.arange(1,lm_sg.shape[1]+1)/sr_meg\n",
    "\n",
    "        # average over the duration of the phoneme for each band:\n",
    "        # resulting array is of shape (nr_epochs, nr_bands+1, nr_timepoints)\n",
    "        epochs = epoch_events(lm_sg, lm_time, onset_df=df_phonemes, sr_meg=sr_meg)\n",
    "        \n",
    "        # stack for all runs:\n",
    "        y_matrix_all_runs = np.vstack((y_matrix_all_runs, epochs))\n",
    "        \n",
    "    return y_matrix_all_runs\n",
    "\n",
    "def init_phoneme_avg_sg(subject:int, session:int, task= '0', dataset='Armani', n_mels=128, \n",
    "                        only_word_inital_phonemes=True):\n",
    "    '''\n",
    "    Params:\n",
    "    -------\n",
    "    - Dataset: 'Armani' or Gwilliams\n",
    "    - Subject\n",
    "    - Session\n",
    "    - n_mels: nr of bands for the mel spectogram\n",
    "    - power\n",
    "    - only_word_inital_phonemes: whether or not only to consider word-inital phonemes\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Array of shape (nr_initial_phonemes, n_mels)\n",
    "    containing the spectogram information averaged over time for each mel band \n",
    "    '''\n",
    "    avg_sg_all_runs = np.empty(shape=(0, n_mels+1)) # +1 for the variance \n",
    "    \n",
    "    if dataset == 'Armani':\n",
    "        audio_dir = '/project/3018059.03/data/Armani/stimuli/'\n",
    "        # sampling rate MEG data:\n",
    "        sr_meg = 1200\n",
    "        \n",
    "    if dataset == 'Gwilliams':\n",
    "        audio_dir = '/project/3018059.03/data/Gwilliams/'\n",
    "        # sampling rate MEG data:\n",
    "        sr_meg = 1000\n",
    "        \n",
    "    # get runs in this session\n",
    "    runs = get_runs(dataset, session, subject, task)\n",
    "\n",
    "    \n",
    "    for run in runs:\n",
    "        \n",
    "        print(run)\n",
    "        \n",
    "        # get onset times of the initial phonemes adjusted to onset of the audiofile:\n",
    "        df_phonemes = get_phonemes_onsets_offsets(dataset, subject, session, run, task, only_word_inital_phonemes)\n",
    "        \n",
    "        \n",
    "        # audio file name \n",
    "        if session<10:\n",
    "            audio_run = audio_dir + '0{}_{}.wav'.format(session, run)\n",
    "        else:\n",
    "            audio_run = audio_dir + '{}_{}.wav'.format(session, run)\n",
    "            \n",
    "        if dataset == 'Gwilliams':\n",
    "            audio_run = audio_dir + df_phonemes.sound.unique()[0]\n",
    "\n",
    "        # waveform (scale) and sampling rate (sr)\n",
    "        scale, sr = librosa.load(audio_run, sr=sr_meg*18)\n",
    "\n",
    "        # make spectrogram \n",
    "        mel_sg   = librosa.feature.melspectrogram(y=scale, sr=sr, hop_length=int(sr/sr_meg), \n",
    "                                                  n_mels=n_mels)\n",
    "        lm_sg    = librosa.power_to_db(mel_sg)\n",
    "        lm_time  = np.arange(1,lm_sg.shape[1]+1)/sr_meg\n",
    "        \n",
    "        # average over the duration of the phoneme for each band:\n",
    "        # resulting array is of shape (nr_phonemes, nr_bands)\n",
    "        discrete_events = discretise_events(lm_sg, lm_time, onset_df=df_phonemes)\n",
    "        \n",
    "        # stack for all runs:\n",
    "        avg_sg_all_runs = np.vstack((avg_sg_all_runs, discrete_events))\n",
    "        \n",
    "    return avg_sg_all_runs\n",
    "\n",
    "def epoch_events(spectogram, times, onset_df, sr_meg):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    - spectogram: librosa mel spectrogram in db\n",
    "        spectrogram of a given run, of shape (n_mels, sampling_rate*seconds) with sampling_rate = MEG_sr *18\n",
    "    - times: numpy array\n",
    "        containing the times in seconds corresponding to each time point in the spectogram\n",
    "    - onset_df: pandas DataFrame\n",
    "        containing a column 'onset' and 'offset' indicating the onset of each word-initial phoneme in seconds\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - numpy ndarray of shape (n_epochs, n_mels+1, n_timepoints) with n_timepoints = 4s * MEG_sampling_rate\n",
    "        containing the envelope and the mels for each epoch\n",
    "    '''\n",
    "\n",
    "    audio={'audio':spectogram,'times':times}\n",
    "        \n",
    "    # np array of shape (onsets, bands, time_points) \n",
    "    bands = np.zeros((len(onset_df),audio['audio'].shape[0], sr_meg*4))\n",
    "    var   = np.zeros(shape=(len(onset_df), sr_meg*4))\n",
    "\n",
    "    for ph_i,ph_row in enumerate(onset_df.iterrows()):\n",
    "            \n",
    "        # make a logical array for audio timepoints that are part of the epoch [onset-2s, onset+2s):\n",
    "        samps_ix=np.logical_and(audio['times']>ph_row[1]['onset']-2,\n",
    "                                audio['times']<ph_row[1]['onset']+2)\n",
    "        \n",
    "        # get samples for this epoch:\n",
    "        temp = audio['audio'][:,samps_ix]\n",
    "\n",
    "        # check if there are the right amount of samples for the epoch, i.e. 4s * MEG_sampling rate\n",
    "        # and pad with zeros either to the left (beginning of audio run) or right (end of audio run)\n",
    "        if temp.shape[1] < sr_meg*4:\n",
    "            if ph_i < len(onset_df)/2: \n",
    "                temp = pad_left(temp, sr_meg*4)\n",
    "            else:\n",
    "                temp = pad_right(temp, sr_meg*4)\n",
    "        \n",
    "        bands[ph_i]= temp\n",
    "\n",
    "    # compute variance over bands for each time point:\n",
    "    var = np.var(bands, axis=1)\n",
    "\n",
    "    # swap axis so mels are dimension 0  \n",
    "    bands = np.swapaxes(bands, 0, 1)\n",
    "\n",
    "    # make array to hold variance and bands, has shape (n_mels+1, n_epochs, n_timepoints)\n",
    "    band_stats     = np.zeros(shape=(bands.shape[0]+1, bands.shape[1], bands.shape[2]))\n",
    "    band_stats[0]  = var\n",
    "    band_stats[1:] = bands\n",
    "        \n",
    "    # scrub nans \n",
    "    band_stats[np.isnan(band_stats)]=0\n",
    "\n",
    "    # swap axes again to have epochs first ... easier for stacking:\n",
    "    band_stats = np.swapaxes(band_stats, 0, 1)\n",
    "    \n",
    "    return(band_stats)\n",
    "\n",
    "def get_phonemes_onsets_offsets(dataset:str, subject:int, session:int, run:int, task='0',\n",
    "                                only_word_inital_phonemes=True):\n",
    "    '''\n",
    "    Params:\n",
    "    - raw_data object\n",
    "    - dataset: dataset for which the offsets are supposed to be loaded: Gwilliams, Armani or sherlock\n",
    "    - subject: subject for which the offsets are supposed to be loaded\n",
    "    - session: session for which the offsets are supposed to be loaded\n",
    "    - run: run for which the offsets are supposed to be loaded\n",
    "    - only_word_inital_phonemes: whether or not to get only word-inital phonemes\n",
    "    \n",
    "    Returns:\n",
    "    - pandas data frame with at least with 3 columns: phoneme, onset  \n",
    "    \n",
    "    '''\n",
    "    if dataset == 'Armani':\n",
    "        \n",
    "        # handle naming of session 10: \n",
    "        if session < 10:\n",
    "            sess = '00' + str(session)\n",
    "        else: \n",
    "            sess = '0' + str(session)\n",
    "        \n",
    "        # get path to events file:\n",
    "        dir_path = '/project/3018059.03/data/Armani/'\n",
    "        filepath = 'sub-00' + str(subject) +'/' + 'ses-' + sess +'/'+ 'meg/'\n",
    "        filename = 'sub-00' + str(subject) + '_ses-' + sess + '_task-compr_events.tsv'\n",
    "        \n",
    "        # read pandas DataFrame for the entire session:\n",
    "        annotations = pd.read_csv(dir_path+filepath+filename, sep='\\t')\n",
    "        \n",
    "        # get list with word_onsets for this run:\n",
    "        word_onset_name = ['word_onset_0{}'.format(run)]\n",
    "        df_words        = annotations[annotations.type.isin(word_onset_name)]\n",
    "        df_words        = df_words[df_words.value != 'sp']\n",
    "        word_onsets     = df_words.onset\n",
    "        \n",
    "        # now look for the timing of the audio onset for this run:\n",
    "        index_first_word = df_words.index[0] # index for the first word in this run\n",
    "        \n",
    "        for i in np.arange(index_first_word, -1, -1):     # interate from there backwards\n",
    "            if annotations.iloc[i].type == 'wav_onset':   # to the most recent wave onset\n",
    "                audio_onset = annotations.iloc[i].onset   # and get it's onset time\n",
    "                break                                     # break out of for loop\n",
    "        \n",
    "        # get list with phoneme_onsets for this run::\n",
    "        onset_name = ['phoneme_onset_0{}'.format(run)]\n",
    "        \n",
    "        # get only phonemes and clean data frame\n",
    "        df_phonemes = annotations[annotations.type.isin(onset_name)]\n",
    "        \n",
    "        if only_word_inital_phonemes:\n",
    "            df_phonemes = df_phonemes[df_phonemes.onset.isin(word_onsets)]\n",
    "        else: df_phonemes = df_phonemes[df_phonemes.value != 'sp']\n",
    "        \n",
    "        #convert times to audio onset times:\n",
    "        df_phonemes.onset = df_phonemes.onset - audio_onset\n",
    "        \n",
    "        # add a column with the offsets:\n",
    "        offsets               = df_phonemes.onset + df_phonemes.duration\n",
    "        df_phonemes['offset'] = offsets\n",
    "        \n",
    "    if dataset == 'Gwilliams':\n",
    "        \n",
    "        path_dir = '/project/3018059.03/data/Gwilliams/'\n",
    "        file_name = 'annotation_task_'+ task + '.tsv'\n",
    "        \n",
    "        # read pandas DataFrame and keep only sentences (not word lists):\n",
    "        annotations = pd.read_csv(path_dir+file_name, sep='\\t')\n",
    "        annotations = annotations[annotations['condition']=='sentence']\n",
    "        \n",
    "        # keep only this run\n",
    "        story_id    = [float(run)]\n",
    "        df_story    = annotations[annotations.sound_id.isin(story_id)]\n",
    "        \n",
    "        # get list with word_onsets for this run (i.e. story uid):\n",
    "        df_words    = df_story[df_story['kind']=='word']\n",
    "        word_onsets = df_words.start\n",
    "        \n",
    "        # get only phonemes \n",
    "        df_phonemes = df_story[df_story['kind']=='phoneme']\n",
    "        \n",
    "        #re-name start column:\n",
    "        df_phonemes['onset'] = df_phonemes.start\n",
    "        \n",
    "        # add a column with the offsets:\n",
    "        offsets               = df_phonemes.onset[1:].to_list()+[0.08]\n",
    "        df_phonemes['offset'] = offsets\n",
    "        \n",
    "        # and now only keep the word_initial phonemes:\n",
    "        if only_word_inital_phonemes:\n",
    "            df_phonemes = df_phonemes[df_phonemes.start.isin(word_onsets)]\n",
    "    \n",
    "    \n",
    "    return df_phonemes\n",
    "\n",
    "\n",
    "def get_runs(dataset, session, subject, task):\n",
    "    \n",
    "    if dataset == 'Armani':\n",
    "        runs = ASH_runs_in_session(session,subject)\n",
    "        \n",
    "    if dataset == 'Gwilliams':\n",
    "        if task == '0':\n",
    "            runs = np.arange(0, 4)\n",
    "        if task == '1':\n",
    "            runs = np.arange(0, 6)\n",
    "        if task == '2':\n",
    "            runs = np.arange(0, 8)\n",
    "        if task == '3':\n",
    "            runs = np.arange(0, 12)\n",
    "    \n",
    "    if dataset=='Goldstein':\n",
    "        runs = [0]\n",
    "    return runs \n",
    "\n",
    "def discretise_events(spectogram, times, onset_df):\n",
    "\n",
    "    # make dictionary of spectogram and meg sampled time points \n",
    "    audio={'audio':spectogram,'times':times}\n",
    "    \n",
    "    # np array of shape (onsets, bands) for the stats of each band \n",
    "    band_means = np.zeros((len(onset_df),audio['audio'].shape[0]))\n",
    "    var        = np.zeros(shape=(len(onset_df)))\n",
    "\n",
    "    for ph_i,ph_row in enumerate(onset_df.iterrows()):\n",
    "        \n",
    "        # make a logical array for audio timepoints that are part of the phoneme:\n",
    "        samps_ix=np.logical_and(audio['times']>ph_row[1]['onset'],\n",
    "                            audio['times']<ph_row[1]['offset'])\n",
    "        \n",
    "        # Average & variance over these timepoints for each band:\n",
    "        band_means[ph_i,:]= np.mean(audio['audio'][:,samps_ix],axis=1)\n",
    "        var[ph_i]         = np.var(audio['audio'][:,samps_ix])\n",
    "        \n",
    "        # Add as columns\n",
    "        band_stats = np.c_[band_means, var]\n",
    "        \n",
    "    # scrub nans \n",
    "    band_stats[np.isnan(band_stats)]=0\n",
    "    \n",
    "    return(band_stats)\n",
    "\n",
    "def get_words_onsets_offsets(dataset:str, subject:int, session:int, run:int, task='0'):\n",
    "    '''\n",
    "    Params:\n",
    "    - raw_data object\n",
    "    - dataset: dataset for which the offsets are supposed to be loaded: Gwilliams, Armani or sherlock\n",
    "    - subject: subject for which the offsets are supposed to be loaded\n",
    "    - session: session for which the offsets are supposed to be loaded\n",
    "    - run: run for which the offsets are supposed to be loaded\n",
    "    \n",
    "    Returns:\n",
    "    - pandas data frame with at least with 3 columns: word, onset, offset \n",
    "    \n",
    "    '''\n",
    "    if dataset == 'Armani':\n",
    "        \n",
    "        # handle naming of session 10: \n",
    "        if session < 10:\n",
    "            sess = '00' + str(session)\n",
    "        else: \n",
    "            sess = '0' + str(session)\n",
    "        \n",
    "        # get path to events file:\n",
    "        dir_path = '/project/3018059.03/data/Armani/'\n",
    "        filepath = 'sub-00' + str(subject) +'/' + 'ses-' + sess +'/'+ 'meg/'\n",
    "        filename = 'sub-00' + str(subject) + '_ses-' + sess + '_task-compr_events.tsv'\n",
    "        \n",
    "        # read pandas DataFrame for the entire session:\n",
    "        annotations = pd.read_csv(dir_path+filepath+filename, sep='\\t')\n",
    "        \n",
    "        # get list with word_onsets for this run:\n",
    "        word_onset_name = ['word_onset_0{}'.format(run)]\n",
    "        df_words        = annotations[annotations.type.isin(word_onset_name)]\n",
    "        df_words        = df_words[df_words.value != 'sp']\n",
    "        word_onsets     = df_words.onset\n",
    "        \n",
    "        # now look for the timing of the audio onset for this run:\n",
    "        index_first_word = df_words.index[0] # index for the first word in this run\n",
    "        \n",
    "        for i in np.arange(index_first_word, -1, -1):     # interate from there backwards\n",
    "            if annotations.iloc[i].type == 'wav_onset':   # to the most recent wave onset\n",
    "                audio_onset = annotations.iloc[i].onset   # and get it's onset time\n",
    "                break                                     # break out of for loop\n",
    "        \n",
    "        #convert times to audio onset times:\n",
    "        df_words.onset = df_words.onset - audio_onset\n",
    "        \n",
    "        # add a column with the offsets:\n",
    "        offsets               = df_words.onset + df_words.duration\n",
    "        df_words['offset'] = offsets\n",
    "        \n",
    "    if dataset == 'Gwilliams':\n",
    "        \n",
    "        path_dir = '/project/3018059.03/data/Gwilliams/'\n",
    "        file_name = 'annotation_task_'+ task + '.tsv'\n",
    "        \n",
    "        # read pandas DataFrame and keep only sentences (not word lists):\n",
    "        annotations = pd.read_csv(path_dir+file_name, sep='\\t')\n",
    "        annotations = annotations[annotations['condition']=='sentence']\n",
    "        \n",
    "        # keep only this run\n",
    "        story_id    = [float(run)]\n",
    "        df_story    = annotations[annotations.sound_id.isin(story_id)]\n",
    "        \n",
    "        # get list with word_onsets for this run (i.e. story uid):\n",
    "        df_words    = df_story[df_story['kind']=='word']\n",
    "        \n",
    "        #re-name start column:\n",
    "        df_words.rename(columns={'start': 'onset'}, inplace=True)\n",
    "        \n",
    "        # add a column with the offsets:\n",
    "        offsets            = df_words.onset[1:].to_list()+[df_words.onset.iloc[-1] + 0.08]\n",
    "        df_words['offset'] = offsets\n",
    "        \n",
    "    if dataset == 'Goldstein':\n",
    "        \n",
    "        dir_path  = '/Users/ines/research/Lingpred/audio/'\n",
    "        file_name =  'podcast_transcript.csv'\n",
    "        filepath  = dir_path + file_name\n",
    "\n",
    "        df_words = pd.read_csv(filepath, sep=',')\n",
    "        df_words.rename(columns={'start': 'onset', 'end': 'offset'}, inplace=True)\n",
    "\n",
    "    return df_words\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
