{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd142a9",
   "metadata": {},
   "source": [
    "# Encoding the Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f64331f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7640592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os \n",
    "import pickle \n",
    "import numpy as np\n",
    "import spacy\n",
    "import seaborn as sns\n",
    "import matplotlib as plt \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../lingpred_new/\"))\n",
    "from plotting import times_100, lowerCI, upperCI, reshape, colours\n",
    "from encoding_analysis import regress_out_one, make_arbitrary_static_vectors, brainscore_no_coef\n",
    "from utils import get_words_onsets_offsets, get_indices_per_task, make_y_matrix_per_run, get_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "424fb8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5136"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the dataset:\n",
    "# -------------------\n",
    "dataset = 'Goldstein' # or \n",
    "#dataset = 'Armeni'\n",
    "#dataset = 'Gwilliams'\n",
    "\n",
    "# type of audio data:\n",
    "use_real_word_offsets = True\n",
    "\n",
    "# dummy variables needed for that get_run functions\n",
    "session = 1\n",
    "subject = 1\n",
    "task    = '0'\n",
    "\n",
    "# Let's get the dataframe containing the words:\n",
    "runs     = get_runs(dataset, session, subject, task)\n",
    "words_df = pd.DataFrame() \n",
    "for run in runs:\n",
    "    if len(runs)==1:\n",
    "        words_df = get_words_onsets_offsets(dataset, subject=subject, session=session, run=run)\n",
    "    else: \n",
    "        temp     = get_words_onsets_offsets(dataset, subject=subject, session=session, run=run)\n",
    "        words_df = pd.concat([words_df, temp])\n",
    "        \n",
    "len(words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9912796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5136, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the appropriate acoustic model:\n",
    "\n",
    "if use_real_word_offsets:     \n",
    "    with open('../audio/{}/acoustic_model_8_mels_averaged_per_word_using_word_offsets.pkl'.format(dataset), 'rb') as f:\n",
    "        acoustics = pickle.load(f)\n",
    "else:   \n",
    "    with open('../audio/{}/acoustic_model_8_mels_averaged_per_word_using_next_word_onset_as_offset.pkl'.format(dataset), 'rb') as f:\n",
    "        acoustics = pickle.load(f)\n",
    "\n",
    "acoustics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07e1bfd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5136, 157)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Compute the indices for making the y matrix\n",
    "# -------------------------------------------\n",
    "# This is already saved under audio/<dataset>/indices_all_tasks.pkl\n",
    "# No need to run this again, as this would take  approx. 10 min\n",
    "\n",
    "indices = get_indices_per_task(dataset)\n",
    "indices.shape\n",
    "\n",
    "dir_path = '../audio/{}/'.format(dataset)\n",
    "file_name = 'indices_all_tasks.pkl'\n",
    "path      = dir_path + file_name\n",
    "\n",
    "print(path)\n",
    "f = open(path,\"wb\")\n",
    "pickle.dump(indices, f)\n",
    "f.close()\n",
    "\n",
    "'''\n",
    "\n",
    "# load the indices:\n",
    "if dataset in ['Goldstein', 'Gwilliams']:\n",
    "    with open('../audio/{}/indices_all_tasks.pkl'.format(dataset), 'rb') as f:\n",
    "        indices = pickle.load(f)\n",
    "if dataset == 'Armeni':\n",
    "    with open('../audio/Armeni/indices_session_1.pkl', 'rb') as f:\n",
    "        indices = pickle.load(f)\n",
    "\n",
    "\n",
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adbc2252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acoustic y matrix of shape (length, 157, dimensionality)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5136, 157, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use indices to make an acoustic y matrix of shape (length, 157, dim)\n",
    "y_acoustics = make_y_matrix_per_run(acoustics, indices)\n",
    "print('Acoustic y matrix of shape (length, 157, dimensionality)')\n",
    "y_acoustics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6de51127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>onset</th>\n",
       "      <th>offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Act</td>\n",
       "      <td>3.710</td>\n",
       "      <td>3.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one,</td>\n",
       "      <td>3.990</td>\n",
       "      <td>4.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>monkey</td>\n",
       "      <td>4.651</td>\n",
       "      <td>4.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in</td>\n",
       "      <td>4.951</td>\n",
       "      <td>5.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>5.051</td>\n",
       "      <td>5.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>middle.</td>\n",
       "      <td>5.151</td>\n",
       "      <td>5.391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  onset  offset\n",
       "0      Act  3.710   3.790\n",
       "1     one,  3.990   4.190\n",
       "2   monkey  4.651   4.931\n",
       "3       in  4.951   5.011\n",
       "4      the  5.051   5.111\n",
       "5  middle.  5.151   5.391"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us look at what our words dataframe looks like at the moment:\n",
    "words_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "117d6f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5136, 5136)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make spacy doc of the text\n",
    "nlp     = spacy.load('en_core_web_lg')\n",
    "text    = \" \".join(words_df[\"word\"].astype(str))\n",
    "doc     = nlp(text)\n",
    "\n",
    "# since our doc is longer than our dataframe we have to match PoS to fit the dataframe\n",
    "# (words like \"there's\" are two words in the doc but one in the dataframe)\n",
    "matched_PoS = []\n",
    "token_idx   = 0\n",
    "\n",
    "for word in words_df['word']:\n",
    "    # get the PoS of the current token\n",
    "    if token_idx < len(doc):\n",
    "        matched_PoS.append(doc[token_idx].pos_)\n",
    "        # advance token_idx until the next word boundary\n",
    "        token_idx += len(nlp(word))  # number of spaCy tokens in this word\n",
    "    else:\n",
    "        # fallback if doc ends unexpectedly\n",
    "        matched_PoS.append(None)\n",
    "\n",
    "len(matched_PoS), len(words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdd19028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>onset</th>\n",
       "      <th>offset</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration previous word</th>\n",
       "      <th>PoS</th>\n",
       "      <th>previous PoS</th>\n",
       "      <th>word_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Act</td>\n",
       "      <td>3.710</td>\n",
       "      <td>3.790</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one,</td>\n",
       "      <td>3.990</td>\n",
       "      <td>4.190</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.08</td>\n",
       "      <td>NUM</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>monkey</td>\n",
       "      <td>4.651</td>\n",
       "      <td>4.931</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.20</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NUM</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in</td>\n",
       "      <td>4.951</td>\n",
       "      <td>5.011</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>ADP</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>5.051</td>\n",
       "      <td>5.111</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>DET</td>\n",
       "      <td>ADP</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>middle.</td>\n",
       "      <td>5.151</td>\n",
       "      <td>5.391</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>DET</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  onset  offset  duration  duration previous word    PoS  \\\n",
       "0      Act  3.710   3.790      0.08                    0.00  PROPN   \n",
       "1     one,  3.990   4.190      0.20                    0.08    NUM   \n",
       "2   monkey  4.651   4.931      0.28                    0.20   NOUN   \n",
       "3       in  4.951   5.011      0.06                    0.28    ADP   \n",
       "4      the  5.051   5.111      0.06                    0.06    DET   \n",
       "5  middle.  5.151   5.391      0.24                    0.06   NOUN   \n",
       "\n",
       "  previous PoS  word_index  \n",
       "0         None           0  \n",
       "1        PROPN           1  \n",
       "2          NUM           2  \n",
       "3         NOUN           3  \n",
       "4          ADP           4  \n",
       "5          DET           5  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# amend the words dataframe with useful information:\n",
    "words_df['duration']              = words_df['offset'] - words_df['onset']\n",
    "words_df['duration previous word']= words_df['duration'].shift(1)\n",
    "words_df['PoS']                   = matched_PoS\n",
    "words_df['previous PoS']          = words_df['PoS'].shift(1)\n",
    "words_df['word_index']            = range(len(words_df))\n",
    "\n",
    "# avoid having NaNs (for the first word the duration of the previous words is undefined)\n",
    "words_df.loc[0, 'duration previous word'] = 0\n",
    "\n",
    "# Let us look at what our words dataframe looks like at the moment:\n",
    "words_df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430c5ae2",
   "metadata": {},
   "source": [
    "### Getting the X Matrices: GPT, GloVe and Arbitrary vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56382603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arbitrary vectors have shape: (5136, 300)  and residualised:  (5135, 300)\n",
      "GloVe vectors have shape: (5136, 300)  and residualised:  (5135, 300)\n",
      "GPT vectors have shape: (5136, 1600)  and residualised:  (5135, 1600)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make X matrices for arbitrary vectors        \n",
    "X_arbitrary  = make_arbitrary_static_vectors(words_df, dim=300)\n",
    "\n",
    "# Get GloVe vectors:\n",
    "X_Glove = np.vstack([nlp(word).vector for word in words_df.word]) # np array of shape (nr_words, 300)\n",
    "\n",
    "# Get GPT vectors:\n",
    "if dataset == 'Goldstein':  \n",
    "    with open('../audio/Goldstein/X_GPT_original_and_residualised_layer_47.pkl', 'rb') as f:\n",
    "        X_matrices_GPT     = pickle.load(f)\n",
    "        X_GPT              = X_matrices_GPT['X_GPT_layer_47']\n",
    "elif dataset == 'Armeni':\n",
    "    with open('../audio/Armeni/X_y_matrices_Glove_GPT_arbitrary_session_1.pkl', 'rb') as f:\n",
    "        X_matrices_GPT     = pickle.load(f)\n",
    "        X_GPT              = X_matrices_GPT['X_GPT']\n",
    "\n",
    "# make X matrices with residualised vectors:\n",
    "X_arbitrary_residualised = regress_out_one(X_arbitrary)\n",
    "X_Glove_residualised     = regress_out_one(X_Glove)\n",
    "X_GPT_residualised       = regress_out_one(X_GPT)\n",
    "\n",
    "print('Arbitrary vectors have shape:', X_arbitrary.shape, ' and residualised: ', X_arbitrary_residualised.shape)\n",
    "print('GloVe vectors have shape:', X_Glove.shape, ' and residualised: ', X_Glove_residualised.shape)\n",
    "print('GPT vectors have shape:', X_GPT.shape, ' and residualised: ', X_GPT_residualised.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e10638",
   "metadata": {},
   "source": [
    "### Audio Encoding: Main Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742a8b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute encoding for original GloVe and arbitrary vectors:\n",
    "y = y_acoustics\n",
    "y = np.swapaxes(np.swapaxes(y, 0, 1), 0, 2)\n",
    "print('y should be of shape: (nr_mels, nr_words, nr_timepoints')\n",
    "print('y has shape ', y.shape)\n",
    "\n",
    "encoding_arbitrary = brainscore_no_coef(X_arbitrary, y)\n",
    "encoding_Glove     = brainscore_no_coef(X_Glove, y)\n",
    "encoding_GPT       = brainscore_no_coef(X_GPT, y)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encoding_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
